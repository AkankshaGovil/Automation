import cdr
import logging
import os
import os.path
import pexpect
import socket
import string
import msw
import unittest
from   time import *
#36909
import socket

class DataCollectorError(Exception):
    "An error occurred during data collection"
    
class DataCollector(object):
    """
    Abstract class for data collection.

    name -- a name so you can find this thing later

    host -- name or IP address of the system where the data is to be
    collected 

    path -- the path to the file (later could be a socket or whatever)

    Most methods involve state changes, so private methods are defined
    for the developer to override.  This relieves the developer from
    being concerned about state.
    """
    def __init__(self, context, name, path=None):
        self.name       = name
        self.mswpath    = path
        self.msw        = context['mswinfo']
        
       
        # Determine if we are running in and SCM configuration
        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            self.bkupmsw    = context['bkupinfo']
            self.bkuptemp2  = 'bkupcdr2'
            self.pktemp2  = 'bkupkt2.pcap'

        # Set the path for test result data
        self.datestamp  = context['nextest.datestamp']
        self.resultroot = context['nextest.result_path']
        self.resultpath = self.resultroot
        self.resultfile = None
        self.resultlist = []
        self.resultprefix=context['qmtest.id'].replace('.', '-')
        
        # Connect to logging started earlier
        self.log = log  = logging.getLogger('nextestlog')
        self._state = "init"

    def getRelResultFile(self):
        """Return the path to the result file relative to the top of the test
        database.

        If the caller invokes this method prior to calling start(), an
        exception will be raised.  This is because the result file name
        is not defined until the collector is started."""
        
        if self._state == "init":
            raise DataCollectorError("Data collector not yet started")
        filename = "%s" % (self.resultfile)
        self.log.debug("getRelResultFile: %s" % filename)
        return filename
    
    def start(self, context):
        """Begin the collection process.

        The start method begins the collection process.  This method is
        generic and simply changes the state of the object.  Subclasses are
        responsible for doing specific actions to get the data.
        """
        if self._state == 'running':
            print '%s: already started' % self.name
            return
        self._startCollect(context)
        self._state = 'running'

    def stop(self, context):
        if self._state != 'running':
            raise DataCollectorError(
                'start: %s is not running' % self.name)
        self._stopCollect(context)
        self._state = 'stopped'

    def fetch(self, context, resultfile):
        """Fetch the data to a local file.

        path -- the local path to copy to
        
        This method does not save data to the test result database.  Use it
        when you want to retrieve data and process it prior to (or instead of)
        saving it with the test results.
        
        If you want to save the data in the results database, use saveResult()
        instead. 
        """
        if self._state == 'running':
            print "fetch: stopping %s before fetch" % self.name
            self.stop()
        self._fetch(context, resultfile)

    def saveResult(self, context, resultfile):
        """Save data to the test result database.

        context -- test execution context from QMTest
        
        path -- the relative path to copy the data to within the results
        database
        
        Write the data to the named path within the pre-defined results
        directory.  The name of the file must be a relative path.
        """
        if self._state == 'running':
            self.stop(context)
        if not os.path.isdir(self.resultpath):
            os.makedirs(self.resultpath)
        self._fetch(context, resultfile)
        
    def _startCollect(self, context):
        raise NotImplementedError

    def _stopCollect(self, context):
        raise NotImplementedError

    def _fetch(self, context, resultfile):
        raise NotImplementedError

class CDRCollectorError(Exception):
    "General exception for CDR collection"
    
class CDRCollector(DataCollector):
    """Collects CDR data from MSW.

    Clears the CDR file and returns whatever gets written to it
    between start and stop.
    """

    def _startCollect(self, context):
        m = self.msw
        self.cdrpath = m.cdrcurrent
        self.calllegscdrpath = m.calllegscdrcurrent
        # PR 1330009
        # Add the cdr path to the context variable to be used later in cdrMapping
        context['cdrCurrentPath']=m.cdrcurrent
        #Find thhe name of the interim CDR file
        temp1=self.cdrpath.split('.')[0]
        self.interimCdr= m.interimcdrcurrent

        #PR 153329

        self.timeCdr= temp1 +'.CTT' 
          
        #Ticket 36101 - Don't clear the CDR file when codenomicon test suite is running
        if not context['qmtest.id'].__contains__('codenomicon'):
            # Clear the consolidated CDR file
            # Ticket - 34248 clear the file only if it exists
            clearcmd= 'if [ -e '+ self.cdrpath + ' ]; then > '+ self.cdrpath + ' ; fi'
            self.log.info('log clear command %s' %clearcmd)
            m.ssh.sendline(clearcmd)
            if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
                mb = self.bkupmsw
                self.bkupcdrpath = mb.cdrcurrent
                #Ticket - 34248
                clearcmd= 'if [ -e '+ self.bkupcdrpath + ' ]; then > '+ self.bkupcdrpath + ' ; fi'
                mb.ssh.sendline(clearcmd)

            try:
                m.ssh.expect(m.prompt, 2)
                if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
                    mb.ssh.expect(mb.prompt, 2)
            except Exception, e:
                #14000
                msg = 'Exception: %s - Error clearing CDR file %s' % (str(e),self.cdrpath)
                self.log.error(msg)
                raise CDRCollectorError(msg)
            self.log.info('CDRCollector: cleared CDR file %s' % self.cdrpath)

            # Clear the call legs CDR file
            #Ticket - 34248
            clearcmd= 'if [ -e '+ self.calllegscdrpath + ' ]; then > '+ self.calllegscdrpath + ' ; fi'
            m.ssh.sendline(clearcmd)
            # Do the same for SCM backup, if configured
            if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
                mb = self.bkupmsw
                self.bkupcalllegscdrpath = mb.calllegscdrcurrent
                #Ticket - 34248
                clearcmd= 'if [ -e '+ self.bkupcalllegscdrpath + ' ]; then > '+ self.bkupcalllegscdrpath + ' ; fi'
                mb.ssh.sendline(clearcmd)

            try:
                m.ssh.expect(m.prompt, 2)
                if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
                    mb.ssh.expect(mb.prompt, 2)
            except Exception, e:
                #14000
                msg = 'Exception: %s - Error clearing Call Legs CDR file %s' % (str(e),self.calllegscdrpath)
                self.log.error(msg)
                raise CDRCollectorError(msg)
            #PR 133009 Changed the log, earlier it was printing cdrpath and not calllegscdrpath
            self.log.info('CDRCollector: cleared Call Legs CDR file %s' % self.calllegscdrpath)
            
            # Clear the INTERIM CDR file
            #PR - 133009
            clearcmd= 'if [ -e '+ self.interimCdr + ' ]; then echo > '+ self.interimCdr + ' ; fi'
            m.ssh.sendline(clearcmd)
            # Do the same for SCM backup, if configured
            if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
                mb = self.bkupmsw
                self.bkupinterimcdrpath = mb.interimcdrcurrent
                clearcmd= 'if [ -e '+ self.bkupinterimcdrpath + ' ]; then echo > '+ self.bkupinterimcdrpath + ' ; fi'
                mb.ssh.sendline(clearcmd)

            try:
                m.ssh.expect(m.prompt, 2)
                if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
                    mb.ssh.expect(mb.prompt, 2)
            except Exception, e:
                msg = 'Exception: %s - Error clearing INTERIM CDR file %s' % (str(e),self.interimCdr)
                self.log.error(msg)
                raise CDRCollectorError(msg)
            self.log.info('CDRCollector: cleared Interim CDR file %s' % self.interimCdr)


 
 
    def _stopCollect(self, context):
        # nothing to do - MSWInfo will clean up on its own
        pass
        
    def _fetch(self, context, resultfile):
        "Fetch data to result path"

        #-------------------------------------------------------------------
        # Set up file paths/names for local results storage
        #-------------------------------------------------------------------
        self.resultfile = '%s_%s' % (self.resultprefix, resultfile)
        calllegsfile = '%s_%s' % (self.resultprefix, 'calllegscdr.dat')
        localpath = self.resultpath + "/" + self.resultfile
        localcalllegspath = self.resultpath + "/" + calllegsfile
        #PR 133009
        #adding another path for the start1 files
        localstart1path = self.resultpath + "/" + "%s_%s" %(self.resultprefix,'start1.dat')
        localinterimpath = self.resultpath + "/" + "%s_%s" %(self.resultprefix,'interim.dat')
        #print localinterimpath

        #-------------------------------------------------------------------
        # Get the CDR files from the MSW and save them in results
        #-------------------------------------------------------------------
        # Per Gayatri, allow some time to be sure CDRs, (especially hunt 
        # CDRs), are written subsequent to call tear-down. 
        sleep(4)

        # Get main consolidated CDR file (end1 CDRs)
        remotepath =  'root@%s:%s' % (self.msw.ipaddr, self.cdrpath)
        cmd = 'scp -q %s %s' %  (remotepath, localpath)
        self.log.debug("CDRCollector._fetch: %s" % cmd)
        os.system(cmd)

        # Ticket-29188: Moved the block of code which copies call leg CDR file
        # down so that the scp is done after CDR path is modified upon date
        # change.

        # verify that we got the consolidated CDR file.
        remotepath =  'root@%s:%s' % (self.msw.ipaddr, self.cdrpath)
        self.log.debug("Checking if path %s exists" % localpath)
        if not os.path.isfile(localpath):
            # Ticket-29188: Get the new CDR path(s) from the MSx. The path
            # must be modified if there is a date change.
            m = self.msw
            m.cdrpath, m.cdrfile, m.calllegscdrfile, m.interimcdrfile, m.cdrcurrent,\
                       m.calllegscdrcurrent, m.interimcdrcurrent = m.getCDRPaths()
       
            self.log.debug("Cdrpath set as %s" % m.cdrpath)
            self.log.debug("Cdrfile set as %s" % m.cdrfile)
            self.log.debug("Calllegscdrfile set as %s" % m.calllegscdrfile)
            self.log.debug("Cdrcurrent set as %s" % m.cdrcurrent)
            self.log.debug("Calllegscdrcurrent set as %s" % m.calllegscdrcurrent)
            self.log.debug("CallInterimFile CallInterimCurrent set as %s" %m.interimcdrcurrent)
            self.cdrpath = m.cdrcurrent
            self.calllegscdrpath = m.calllegscdrcurrent
            #PR 1330009
            context['cdrCurrentPath']=m.cdrcurrent
            remotepath =  'root@%s:%s' % (self.msw.ipaddr, self.cdrpath)
            cmd = 'scp -q %s %s' %  (remotepath, localpath)
            self.log.debug("CDRCollector._fetch: %s" % cmd)
            os.system(cmd)
            sleep(2)
            self.log.debug("Checking if path %s exists" % localpath)
            if not os.path.isfile(localpath):
                msg = "failed to copy %s to %s" % (remotepath, localpath)
                raise CDRCollectorError(msg)
        else:
            self.log.info('CDRCollector._fetch: copied mymsw:%s to %s' % (self.cdrpath, localpath))

        # Get call legs CDR file (hunt CDRs and others, if configured)
        # Note: Depending on release, hunt CDRs may be written to either the
        # main consolidated CDR file or the call legs CDR file. Since we
        # combine the two here, tests should be unnafected.
        remotepath =  'root@%s:%s' % (self.msw.ipaddr, self.calllegscdrpath)
        cmd = 'scp -q %s %s' %  (remotepath, localcalllegspath)
        self.log.debug("CDRCollector._fetch: %s" % cmd)
        os.system(cmd)

        # verify that we got the call legs CDR file.
        if not os.path.isfile(localcalllegspath):
            # Ticket-31518: Get the new CDR path(s) from the MSx. The path
            # gets modified whenever there is a date change.
            m = self.msw
            m.cdrpath, m.cdrfile, m.calllegscdrfile, m.interimcdrfile, m.cdrcurrent,\
                       m.calllegscdrcurrent, m.interimcdrcurrent = m.getCDRPaths()
            #m.cdrpath, m.cdrfile, m.calllegscdrfile, m.cdrcurrent,\
            #                             m.calllegscdrcurrent = m.getCDRPaths()
            self.log.debug("Cdrpath set as %s" % m.cdrpath)
            self.log.debug("Cdrfile set as %s" % m.cdrfile)
            self.log.debug("Calllegscdrfile set as %s" % m.calllegscdrfile)
            self.log.debug("Cdrcurrent set as %s" % m.cdrcurrent)
            self.log.debug("Calllegscdrcurrent set as %s" % m.calllegscdrcurrent)
            self.cdrpath = m.cdrcurrent
            self.calllegscdrpath = m.calllegscdrcurrent
            #PR 133009
            context['cdrCurrentPath']=m.cdrcurrent
            remotepath =  'root@%s:%s' % (self.msw.ipaddr, self.cdrpath)
            cmd = 'scp -q %s %s' %  (remotepath, localpath)
            self.log.debug("CDRCollector._fetch: %s" % cmd)
            os.system(cmd)
            sleep(2)
            self.log.debug("Checking if path %s exists" % localpath)
            if not os.path.isfile(localpath):
                msg = "failed to copy %s to %s" % (remotepath, localcalllegspath)
                raise CDRCollectorError(msg)
        else:
            self.log.info('CDRCollector._fetch: copied mymsw:%s to %s' % (self.calllegscdrpath, localcalllegspath))

        #Copying the interim cdrs 
        remotepath =  'root@%s:%s' % (self.msw.ipaddr, self.interimCdr)
        #print localinterimpath
        cmd = 'scp -q %s %s' %  (remotepath, localinterimpath)
        self.log.debug("CDRCollector._fetch: %s" % cmd)
        os.system(cmd)

        if not os.path.isfile(localinterimpath):
            # Ticket-31518: Get the new CDR path(s) from the MSx. The path
            # gets modified whenever there is a date change.
            m = self.msw
            m.cdrpath, m.cdrfile, m.calllegscdrfile, m.interimcdrfile, m.cdrcurrent,\
                       m.calllegscdrcurrent, m.interimcdrcurrent = m.getCDRPaths()

            self.log.debug("Cdrpath set as %s" % m.cdrpath)
            self.log.debug("Cdrfile set as %s" % m.cdrfile)
            self.log.debug("Calllegscdrfile set as %s" % m.calllegscdrfile)
            self.log.debug("Cdrcurrent set as %s" % m.cdrcurrent)
            self.log.debug("Calllegscdrcurrent set as %s" % m.calllegscdrcurrent)
            self.cdrpath = m.cdrcurrent
            self.calllegscdrpath = m.calllegscdrcurrent
            self.interimCdr = m.interimcdrcurrent
            #PR 133009
            context['cdrCurrentPath']=m.cdrcurrent
            remotepath =  'root@%s:%s' % (self.msw.ipaddr, self.cdrpath)
            cmd = 'scp -q %s %s' %  (remotepath, localpath)
            self.log.debug("CDRCollector._fetch: %s" % cmd)
            os.system(cmd)
            sleep(2)
            self.log.debug("Checking if path %s exists" % localpath)
            if not os.path.isfile(localpath):
                msg = "failed to copy %s to %s" % (remotepath, localinterimpath)
                raise CDRCollectorError(msg)
        else:
            self.log.info('CDRCollector._fetch: copied mymsw:%s to %s' % (self.interimCdr, localinterimpath))





        #-------------------------------------------------------------------
        # Combine the call legs CDR file with the main CDR file, produce a 
        # sorted combined file.
        # PR 133009
        # Adding another path for the start1 files
        #-------------------------------------------------------------------
        self.mergeCDRfiles(context, localpath, localcalllegspath, localstart1path, localinterimpath)

        #-------------------------------------------------------------------
        # Append the test ID and the current main CDR file to the collected 
        # CDR log file for this QMtest run.
        #-------------------------------------------------------------------
        self.log.info('CDRCollector._fetch: Append test ID and current main CDR file to collected CDR log file.' )
        testid = context['qmtest.id']
        cmd = 'echo -------------------------------------------- >> %s/CDR.log'\
            % (self.resultroot)
        os.system(cmd)
        cmd = 'echo CDR\(s\) for %s: >> %s/CDR.log' % (testid, self.resultroot)
        os.system(cmd)
        cmd = 'cat %s >> %s/CDR.log' % (localpath, self.resultroot)
        os.system(cmd)
        #36909 - Decoding the CDR data and storing it in to results directory
        decodepath = self.resultpath + "/" + self.resultprefix  + '_cdr.decode'
        cmd = 'cat %s | /tmp/cdr_decode.pl > %s' %(localpath, decodepath)
        os.system(cmd)
        #PR 133009
        # Decoding the start1 cdrs also to the same decode file
        cmd='cat %s | /tmp/cdr_decode.pl >> %s' %(localstart1path,decodepath)
        os.system(cmd)
        # Decoding the interim cdrs 
        decodeinterimpath = self.resultpath + "/" + self.resultprefix  + '_interimcdr.decode'
	if os.path.isfile(decodeinterimpath):
            cmd='cat %s | /tmp/cdr_decode.pl >> %s' %(localinterimpath,decodeinterimpath)
            os.system(cmd)

        #-------------------------------------------------------------------
        # If SCM, get CDR file from backup MSW and save
        #-------------------------------------------------------------------
        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            bkuplocalpath = self.resultpath + "/" + resultfile + ".backup"
            cmd = 'scp -q root@%s:%s %s' % (self.bkupmsw.ipaddr,
                                            self.bkupcdrpath,
                                            bkuplocalpath)
            os.system(cmd)
            self.log.info('CDRCollector._fetch: copied backup CDR file bkupmsw:%s to %s' % \
                   (self.bkupcdrpath, bkuplocalpath))
            # PR - Added to suuport cdr streaming feature

            bkupcalllegsfile = '%s_%s' % (self.resultprefix, 'calllegscdr_bkup.dat')
            bkuplocalcalllegspath = self.resultpath + "/" + bkupcalllegsfile

            cmd = 'scp -q root@%s:%s %s' % (self.bkupmsw.ipaddr,
                                            self.bkupcalllegscdrpath,
                                            bkuplocalcalllegspath)
            os.system(cmd)
            self.log.info('CDRCollector._fetch: copied backup CDR file bkupmsw:%s to %s' % \
                          (self.bkupcalllegscdrpath, bkuplocalcalllegspath))

            bkupinterimfile = '%s_%s' % (self.resultprefix, 'interim_bkup.dat')
            bkuplocalinterimpath = self.resultpath + "/" + bkupinterimfile

            cmd = 'scp -q root@%s:%s %s' % (self.bkupmsw.ipaddr,
                                            self.bkupinterimcdrpath,
                                            bkuplocalinterimpath)
            os.system(cmd)
            self.log.info('CDRCollector._fetch: copied backup CDR file bkupmsw:%s to %s' % \
                          (self.bkupinterimcdrpath, bkuplocalinterimpath))

            self.mergeCDRfiles(context, bkuplocalpath, bkuplocalcalllegspath,interimpath=self.bkupinterimcdrpath)


        #-------------------------------------------------------------------
        # Now parse the CDR file in preparation for assertion processing
        #-------------------------------------------------------------------
        self.log.info('CDRCollector._fetch: Append test ID and current main CDR file to collected CDR log file.' )
        cp = cdr.CDRParser(context, localpath)
        self.resultlist = cp.decode()

        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            bkupcp = cdr.CDRParser(context, bkuplocalpath)
            self.bkupcdrlist = bkupcp.decode()
            self.versionSpecificProcessing(self.msw.iVersion, self.bkupcdrlist)

        #-------------------------------------------------------------------
        # Perform any MSx-release-dependent logic required on the CDR list
        #-------------------------------------------------------------------
        self.versionSpecificProcessing(self.msw.iVersion, self.resultlist)

        #-------------------------------------------------------------------
        # Finaly, publish the CDR list in context for test cases to use
        #-------------------------------------------------------------------
        context['cdrlist'] = self.resultlist

        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            context['cdrlist'].extend(self.bkupcdrlist)             
            #36909 - Decoding the CDR data from bkup and storing it in to results directory
            decodepath1 = self.resultpath + "/" + self.resultprefix  + '_bkupcdr.decode'
            cmd = 'cat %s | /tmp/cdr_decode.pl > %s' %(bkuplocalpath, decodepath1)
            os.system(cmd) 

   # PR 133009
   # Adding another path for the start1 files
    def mergeCDRfiles(self, context, end1filepath, legsfilepath, start1path=None, interimpath=None):
        """Merges CDRs from both CDR files, consolidated (end1) and call legs 
           (hunt), into one file. CDRs are merged and sorted into the new filew 
           in the order they are produced.
        """
        # Prep (strip empty records from) the end1 CDR file
        end1dict=[]
	legsdict=[]
	interimdict=[]
        
	if os.path.isfile(end1filepath):
            i_fd = open(end1filepath, 'r')
            end1list = i_fd.readlines()
            i_fd.close()
            end1list = [x for x in end1list if len(x) > 1]
            i_fd = open(end1filepath, 'w')
            i_fd.writelines(end1list)
            i_fd.close()
            # Make dictionaries from the prepped cdr files
            end1 = cdr.CDRParser(context, end1filepath)
            end1dict = end1.decode()

        # Prep (strip empty records from) the call legs CDR file
	if os.path.isfile(legsfilepath):
            i_fd = open(legsfilepath, 'r')
            legslist = i_fd.readlines()
            i_fd.close()
            legslist = [x for x in legslist if len(x) > 1]
            i_fd = open(legsfilepath, 'w')
            i_fd.writelines(legslist)
            i_fd.close()
            # Make dictionaries from the prepped cdr files
            legs = cdr.CDRParser(context, legsfilepath)
            legsdict = legs.decode()

	if os.path.isfile(interimpath):
            i_fd = open(interimpath, 'r')
            interimlist = i_fd.readlines()
            i_fd.close()
            interimlist = [x for x in interimlist if len(x) > 1]
            i_fd = open(legsfilepath, 'w')
            i_fd.writelines(interimlist)
            i_fd.close()
            # Make dictionaries from the prepped cdr files
            interim = cdr.CDRParser(context, interimpath)
            interimdict = interim.decode()

        # For each end1 cdr...
        i=0
        mergedLines = []
        start1Lines = []
        while i < len(end1dict):
            # ...look at every legs cdr.

            if (end1dict[i]['39-cdr-type'] == "interim"):
                mergedLines.append(end1list[i])
                i=i+1
            j=0
            while j < len(legsdict):
                # PR 133009 - Adding code to write start1 cdr to a separate file
                if (legsdict[j]['39-cdr-type'] == "start1"):
                    start1Lines.append(legslist[j])
                # append all legs cdrs from the same call...
                if end1dict[i]['24-callid'] == legsdict[j]['37-incoming-leg-callid']:
                    mergedLines.append(legslist[j])
                j=j+1
            m=0
            while m < len(interimdict):
                if end1dict[i]['24-callid'] == interimdict[m]['24-callid']:
                    mergedLines.append(interimlist[m])
                m=m+1
         
            # Finally, append end1 cdr from this call to the output file.
            #Ticket 36101 - Do not include the CDRs of Codenomicon test suite
            codi_ip1=socket.gethostbyname('codenomicon1')
            codi_ip2=socket.gethostbyname('codenomicon2')
            codi_ip3=socket.gethostbyname('codenomicon3')
            codi_ip4=socket.gethostbyname('codenomicon4')
            codi_ips = [codi_ip1,codi_ip2,codi_ip3,codi_ip4] 
            # 41101 - Fixed the error in the filter
            if not (end1dict[i]['26-call-source-regid'].__contains__('codi') or \
                    end1dict[i]['28-call-dest-regid'].__contains__('codi') or \
                    end1dict[i]['04-call-source'] in codi_ips or \
                    end1dict[i]['06-call-dest'] in codi_ips ) :
                mergedLines.append(end1list[i])

            i=i+1

        # Copy mergedLines to leg1File
        o_fd = open(end1filepath, 'w')
        o_fd.writelines(mergedLines)
        o_fd.close()
        
        # PR 133009
        # Write start1 cdr to the start1Files
	if start1path != None:
            o_fd_1 = open(start1path, 'w')
            o_fd_1.writelines(start1Lines)
            o_fd_1.close()
        
    def versionSpecificProcessing(self, version, CDRs):
        """
           Perform any special processing that needs to be done to CDRs for
           for different MSW versions.
        """
        #-------------------------------------------------------------------
        # In:
        #     * MSx versions 3.1.2 and 4.1, 
        #     * hunt CDRs, 
        #     * where mapping is not enabled, (30 not null & 60 null)
        #
        # the original isdn cause code received in the REL msg is stored in 
        # the 30-isdn-cause-code field. Current releases correct this and 
        # store this value in 60-original-isdn-cause-code. To provide
        # consistency to test cases, if the above conditions are present, 
        # we assign the isdn-cause-code value to the 
        # original-isdn-cause-code field for purposes of testing causecode.
        # Note that if mapping is turned on, then 60-original-isdn-cause-code
        # will be non-null, and this logic will not be invoked on any CDR.
        #-------------------------------------------------------------------
        if ((self.msw.compareiServerVersion('3.1.2') == 0) or (self.msw.compareiServerVersion('4.1') >= 0)):
            for c in CDRs:
                if c['39-cdr-type'] == 'hunt':
                    # This condition indicates that mapping was not performed on thes call
                    if (c['30-isdn-cause-code'] and not c['60-original-isdn-cause-code']):
                        # So let test know what the original CC received in the REL was
                        c['60-original-isdn-cause-code'] = c['30-isdn-cause-code']





class PktTraceCollectorError(Exception):
    "General exception for PktTrace collector"
    
class PktTraceCollector(DataCollector):
    """Collects Tethereal tcpdump data from MSW.

    Starts tethereal processes on  (eth)0 and (eth)1, collects packet 
    trace data between start and stop, merges them after stop.  The (eth) name
    is determined by querying the OS type of the target.
    """
    def _startCollect(self, context):
        self.mswfile = 'pkttrace.pcap'
        self.mergepath = "%s/%s" % (self.mswpath, self.mswfile)

        m = self.msw

        #SCM testing addon
        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            mb = self.bkupmsw

        # Define parameters for tethereal
        friends = ' \( tcp or udp or icmp or arp \) '
        noEnemies = 'and not tcp port 6000 and not tcp port 22 '
        eth = 'eth'
        if m.ostype == 'SunOS':
            eth = 'e1000g'
        capFileFmt = "%s/pkttrace_%s.pcap"

        # Start the trace on both signaling interfaces
        # Save capture file names in a list
        self.capfile = [] 
        # 50672 - Changing the capture filter interface to any. 
        # Since the packets are filtered based on the below mentioned 
        # ipList it is not required to capture the packets on
        # different interfaces. Hence modified
        interface = "any"
        self.capfile.append(capFileFmt % (self.mswpath, interface))

        #Akanksha
        self.capfile_filter="%s/pkttrace_filter.pcap" %(self.mswpath)
        # Build tethereal command
        # 36909 - Changed capture filter to avoid capturing unwanted packets.
        # 38681 - Modified code to include the other ips
        ipList = []  
        ipList.append(socket.gethostbyname('mymsw'))

	if (context['nextest.scm_configuration'] == 'ON'):
            #PR-149643 Including backup MSX IP so that packets generated from backup MSX can also be included in capture
            ipList.append(socket.gethostbyname('bkupmsw'))

        ipList.append(socket.gethostbyname('pub_rsa'))
        ipList.append(socket.gethostbyname('prv_rsa'))
        ipList.append(socket.gethostbyname('enum_realm'))
        ipList.append(socket.gethostbyname('rh_realm_psx'))
        ipList.append(socket.gethostbyname('gatekeeper1'))
        ipList.append(socket.gethostbyname('gatekeeper2'))

        ipStr = ' or '
        ipStr = ipStr.join(ipList)

        #46277 Use filter to capture required packets only
        # 52678 Use filter to capture sctp packets
        # 52415 Use filter to capture tcp packets also
        # 51218 Use filter to capture udp packets  also, so that radius_pod packets are copied 
        # 52678 Use filter to capture sctp packets
        # 51218 Added udp to the filter to capture radius_pod packets 
        self.pcapfilter = '"sip || h225 || h245 || radius || dns || snmp || sctp || tcp || udp"'

        cmd = ['tethereal',
               ' -i %s ' % interface,
               '-f "(host %s) and not (port 22 or 10101)"' %(ipStr),
               ' -w  %s' % self.capfile[0],
               ' > /dev/null 2>&1 &']

        #       ' -R %s' % pcapfilter,
        # Commenting the code as this increases the time
	##Ticket 59766 
        #cmd = ['tethereal',
        #       ' -i %s ' % interface,
        #       '-f " not (host 127.0.0.1) and not (port 22 or 10101)"',
        #       ' -R %s' % pcapfilter,
        #       ' -w  %s' % self.capfile[0],
	#       '-t a',
        #       ' > /dev/null 2>&1 &']
        cmd = string.join(cmd)
        self.log.debug("cmd = %s" % cmd)
        #print "pcap file%s" %self.capfile[0]

        # Do it
        m.ssh.sendline(cmd)
        try:
            m.ssh.expect(m.prompt, 3)
        except pexpect.TIMEOUT:
            msg = "PktTraceCollector: no response from trace command"
            self.log.error(msg)
            raise PktTraceCollectorError(msg)
        sleep(2)


        #SCM testing addon
        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            mb.ssh.sendline(cmd)
            mb.ssh.expect(mb.prompt)

    def _stopCollect(self, context):
        m = self.msw

        # Kill tethereal
        
        if (context.has_key('mswinfo')) and (context.get('mswinfo') != None):
            m.ssh.sendline('pkill -INT tethereal')
            try:
                m.ssh.expect(m.prompt)
            except pexpect.TIMEOUT:
                msg = "PktTraceCollector: no reponse from pkill tethereal"
                self.log.error(msg)
                raise PktTraceCollectorError(msg)
            self.log.info('PktTraceCollector: STOPPED tethereal on MSW')

        # Kill tethereal on backup MSW
        
        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            mb = self.bkupmsw
            mb.ssh.sendline('pkill -INT tethereal') 
            try:
                mb.ssh.expect(mb.prompt)
            except pexpect.TIMEOUT:
                msg = "PktTraceCollector: no reponse from pkill tethereal"
                self.log.error(msg)
                raise PktTraceCollectorError(msg)
            self.log.info('PktTraceCollector: STOPPED tethereal on backup MSW')
        
        #Akanksha - adding a command to filter the packets into second file
        # as -w and -R no longer wprk togethr

        #tempPcap = "/tmp/tmp.pcap"
        cmd_pkttrace = "tethereal -r %s -R %s -w %s " %(self.capfile[0],self.pcapfilter,self.capfile_filter)
        #print cmd_pkttrace

        cmd = "mergecap -w %s %s" % (self.mergepath,
                                        self.capfile[0])
        #cmd = "mergecap -w %s %s" % (self.mergepath,
        #                                self.capfile_filter)

        #print "pcap file%s" %self.capfile[0]
        if (context.has_key('mswinfo')) and (context.get('mswinfo') != None):
            #m.ssh.sendline(cmd_pkttrace)
            #m.ssh.expect(m.prompt)
            m.ssh.sendline(cmd)
            m.ssh.expect(m.prompt)
            self.log.info('PktTraceCollector: merged to %s' % self.mergepath)
        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            #m.ssh.sendline(cmd_pkttrace)
            #m.ssh.expect(m.prompt)
            mb.ssh.sendline(cmd)
            mb.ssh.expect(mb.prompt)

        # Now exit the remote connection
        self.log.debug('PktTraceCollector: disconnected from %s' % m.ipaddr)
        
    def _fetch(self, context, resultfile):


  
        self.bkupresultpath = '/tmp'
        self.resultfile = '%s_%s' % (self.resultprefix, resultfile)
        m = self.msw
      
        remotepath = "root@%s:%s" % (m.ipaddr, self.mergepath)
        #print "mergepath %s" %self.mergepath

        localpath = self.resultpath + '/' + self.resultfile
        localpath_pdml = self.resultpath + '/' + self.resultfile.replace('pcap', 'pdml')
        
        cmd = 'scp -q %s %s' % (remotepath, localpath)
        os.system(cmd)
        if not os.path.isfile(localpath):
            msg = "failed to copy %s to %s" % (remotepath, localpath)
            raise PktTraceCollectorError(msg)
        self.log.info('PktTraceCollect: copied %s to %s' % (remotepath, localpath))
         
        # 48913 Codes added to mearge msw and bkmsw pcap files
        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
           mb = self.bkupmsw
           remotepath1 = "root@%s:%s" % (mb.ipaddr, self.mergepath)
           localpath1 = self.resultpath + '/' + self.resultfile + ".backup"
           cmd = 'scp -q %s %s' % (remotepath1, localpath1)
           os.system(cmd)
           if not os.path.isfile(localpath1):
               msg = "failed to copy %s to %s" % (remotepath1, localpath1)
               raise PktTraceCollectorError(msg)
           self.log.info('PktTraceCollect: copied %s to %s' % (remotepath,localpath1))
           tmp1 = self.resultpath + '/' + self.resultfile + ".output"
           cmd = 'mergecap -w %s %s %s' %(tmp1, localpath, localpath1)
           #print cmd
           os.system(cmd)
           os.system('cp %s %s' % (tmp1,localpath))

       #create pdml file
        #cmd = 'tethereal -Tpdml -r %s > %s' % (localpath, localpath_pdml)
        cmd = 'tethereal -Tpdml -r %s -R %s > %s' % (localpath,self.pcapfilter,localpath_pdml)
        os.system(cmd) 
        self.log.info('PktTraceCollect: cmd for pdml file %s'  % (cmd))
        if not os.path.isfile(localpath_pdml):
            msg = "failed to generate pdml file %s" % (localpath_pdml)
            raise PktTraceCollectorError(msg)
        self.log.info('PktTraceCollect: generated pdml file %s'  % (localpath_pdml))

    def getPdmlFile(self):
        """Return the path to the pdml file. """
        
        localpath_pdml = self.resultpath + '/' + self.resultfile.replace('pcap', 'pdml')
        if not os.path.isfile(localpath_pdml):
            msg = "pdml file %s does not exist" % (filename)
            raise PktTraceCollectorError(msg)
        self.log.debug("getPdmlFile: %s" % localpath_pdml)
        return localpath_pdml
    
class DbgLogCollectorError(Exception):
    "General exception for DbgLog collector"
    
class DbgLogCollector(DataCollector):
    """Collects gis-genereated debug log data from MSW for flags which 
       have previously been set .

    DbgLogCollector clears iserver.log, then copies it to the output 
    directory on the call generator after test is complete.
    """
    def _startCollect(self, context):
        m = self.msw
        self.dbglogpath = m.dbglogpath
        self.log.debug('DbgLogCollector: Started')
        self.log.debug('DbgLogCollector: m.dbglogpath=%s' % m.dbglogpath)

        # Clear the old log file
        cmd = 'echo > %s' % self.dbglogpath
        m.ssh.sendline(cmd)
        self.log.info('DbgLogCollector: cleared log w/ cmd: %s' % cmd)
        self.log.debug('DbgLogCollector: Started')
        
        # handling SCM case
        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            mb = self.bkupmsw
            self.bkupdbglogpath = mb.dbglogpath
            mb.ssh.sendline('echo > %s' % self.bkupdbglogpath)

        try:
            m.ssh.expect(m.prompt, 3)
            if (context.has_key('bkupinfo'))and(context.get('bkupinfo')!=None):
                mb.ssh.expect(mb.prompt, 3)
                
        except pexpect.TIMEOUT:
            msg = "DbgLogCollector failed to get response from command"
            self.log.error(msg)
            raise DbgLogCollectorError(msg)

        # Initialize a collected dbg log file for this run:
        cmd = 'echo > %s/DBGLOG.log' % (self.resultroot)

    def _stopCollect(self, context):
        self.log.debug('DbgLogCollector: _StopCollect called')

    # Ticket 13391 updates
    
    def __formlogdict(self, logline):
        """
        Form log dictionary from a log line
        """
        # empty dictionary
        logdict = { }

        #split through white spaces
        tokens = logline.split( )

        # update the dictionary
        logdict['date']    = ' '.join(tokens[0:2])
        logdict['time']    = tokens[2]
        logdict['mswname'] = tokens[3]
        logdict['process'] = tokens[4]
        logdict['level']   = tokens[5]
        logdict['module']  = tokens[6]
        logdict['log']     = ' '.join(tokens[7:])

        # return dictionary
        return logdict
    
    def __mswlogParser(self, mswlogfile):
        """
        msw log parser.

        Read the content of file to a list forming a list of lines.
        For each line in the list form a dictionary.
        Add the dictionary to a list to form parsed dictionary list.
        """
        # create empty list of mswlog dictonary
        self.mswloglist = []
        
        # Read the contents of the file to a list
        f = open(mswlogfile, 'r')
        linelist = f.readlines()
        f.close()
        
        # Parse each log line
        for logline in linelist:
            if len(logline) != 0:
                try:
                    logdict = self.__formlogdict(logline)
                    if logdict: self.mswloglist.append(logdict)
                #14000
                except Exception,e:
                    # takes care if there is problem in logline
                    msg = 'Exception: problem in logline  %s  ' % str(e)
                    self.log.error(msg)
                    continue

        # return the parsed output
        return self.mswloglist
        
    def _fetch(self, context, resultfile):
        self.resultfile = '%s_%s' % (self.resultprefix, resultfile)
        m = self.msw
        remotepath = "root@%s:%s" % (m.ipaddr, self.dbglogpath)
        localpath = self.resultpath + '/' + self.resultfile
        cmd = 'scp -q  %s %s' % (remotepath, localpath)
        os.system(cmd)
        self.log.info("DbgLogCollector: copied %s to %s" % (remotepath, localpath))
        if not os.path.isfile(localpath):
            msg = "DbgLogCollector: failed to fetch file to %s" % localpath
            self.log.error(msg)
            raise DbgLogCollectorError(msg)
        
        # Ticket 13391 update
        # If SCM, get log file from backup MSW and save
        
        if (context.has_key('bkupinfo')) and (context.get('bkupinfo') != None):
            bkuppath = self.resultpath + "/" + self.resultfile + ".backup"
            cmd = 'scp -q root@%s:%s %s' % (self.bkupmsw.ipaddr,
                                            self.bkupdbglogpath,
                                            bkuppath)
            os.system(cmd)
            self.log.info('DbgLogCollector: copied file bkupmsw:%s to %s' % \
                          (self.bkupdbglogpath, bkuppath))
            # Now parse the bkup log file
            context['bkupmswLoglist'] = self.__mswlogParser(bkuppath)

        #-------------------------------------------------------------------
        # Append the test ID and the current dbglog file to the collected 
        # dbglog file for this QMtest run.
        #-------------------------------------------------------------------
        self.log.info('DbgLogCollector._fetch: Append test ID and current dbglog file to collected DBGLOG.log file.' )
        testid = context['qmtest.id']
        cmd = 'echo NexTest DbgLog: ---------------------------------------------------------------- >> %s/DBGLOG.log'\
            % (self.resultroot)
        os.system(cmd)
        cmd = 'echo NexTest DbgLog: GIS DbgLog produced by %s >> %s/DBGLOG.log' % (testid, self.resultroot)
        os.system(cmd)
        cmd = 'echo NexTest DbgLog: ---------------------------------------------------------------- >> %s/DBGLOG.log'\
            % (self.resultroot)
        os.system(cmd)
        cmd = 'cat %s >> %s/DBGLOG.log' % (localpath, self.resultroot)
        os.system(cmd)
        cmd = 'echo "\n\n">> %s/DBGLOG.log' % (self.resultroot)
        os.system(cmd)

        # Parse the msw log file for assertion processing
        context['mswLoglist'] = self.__mswlogParser(localpath)

########################################################################
# Unit tests
########################################################################

class MswlogTest(unittest.TestCase):
    """
    Unittest class for testing the parsing part of msw log.
    """

    def testCDRCollector_1(self):
        """
        This test validates if the file creation is successful on local
        machine.

        Instantiating the class will create the files. Then check for the
        presence of these files in the respective path.
        """
        # construct context, required for class instantiation
        context = {}
        context['mswinfo'] = msw.MSWInfo('mymsw')
        context['nextest.result_path'] = '/tmp'
        context['qmtest.id'] = ''
        
        # instantiate the class
        c = CDRCollector(context, 'CallTestCDR')
        c.start(context)
        c.saveResult(context, 'cdr.dat')
        cdrFile = c.getRelResultFile()

    def testMswlogParser(self):
        """
        This test validates if the file creation is successful on local
        machine.

        Instantiating the class will create the files. Then check for the
        presence of these files in the respective path.
        """
	return
        # construct context, required for class instantiation
        context = {}
        context['mswinfo'] = msw.MSWInfo('mymsw')
        context['nextest.result_path'] = '/tmp'
        context['qmtest.id'] = ''
        
        # instantiate the class
        dbgLog = DbgLogCollector(context, 'mymsw')

        # start the log
        dbgLog.start(context)
        
        # create a log file of what we need to see
        log = 'Jul 15 15:23:16 msw20 gis[22326]: DEB:  MSEL: 2 ready for gis'
        cmd = 'echo %s > %s' % (log, dbgLog.dbglogpath)
        dbgLog.msw.ssh.sendline(cmd)
        
        # parse the log file
        dbgLog.stop(context)
        dbgLog.fetch(context, 'mswlogfile')
        parsedList = context['mswloglist']
        
        # Assertions
        self.assertEqual(parsedList[0]['date'], 'Jul 15')
        self.assertEqual(parsedList[0]['time'], '15:23:16')
        self.assertEqual(parsedList[0]['mswname'], 'msw20')
        self.assertEqual(parsedList[0]['process'], 'gis[22326]:')
        self.assertEqual(parsedList[0]['level'], 'DEB:')
        self.assertEqual(parsedList[0]['module'], 'MSEL:')
        self.assertEqual(parsedList[0]['log'], '2 ready for gis')
            

if __name__ == '__main__':
    unittest.main()

        
########################################################################
# Local Variables:
# mode: python
# indent-tabs-mode: nil
# fill-column: 78
# auto-fill-function: do-auto-fill
# End:
